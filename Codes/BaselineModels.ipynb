{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPK2ix7tVIVE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import imageio\n",
    "import medmnist\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import glob\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random \n",
    "import cv2 as cv\n",
    "import math \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# DATA\n",
    "IMG_SIZE = 24\n",
    "BATCH_SIZE = 32\n",
    "FRAME = 10\n",
    "CHANNEL = 1\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "INPUT_SHAPE = (IMG_SIZE, IMG_SIZE, FRAME, CHANNEL)\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# OPTIMIZER\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# TRAINING\n",
    "EPOCHS = 100\n",
    "\n",
    "MODEL_PATH = \"model_h\"\n",
    "RESULT_PATH = \"results_m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1723, 889, 20185, 1723, 889, 20185)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "test_flist = [] \n",
    "val_flist = [] \n",
    "train_flist = [] \n",
    "\n",
    "for cpath, dirs, files in os.walk('HUST-LEBW/training'):\n",
    "    if '.jpg' in ''.join(files):\n",
    "        train_flist += [ cpath + '/' + f for f in files if 'checkpoint' not in cpath]\n",
    "            \n",
    "for cpath, dirs, files in os.walk('HUST-LEBW/test'):\n",
    "    if  '.jpg' in ''.join(files):\n",
    "        val_flist += [ cpath + '/' + f for f in files if 'checkpoint' not in cpath]\n",
    "        \n",
    "for cpath, dirs, files in os.walk('MAEB'):\n",
    "    if '.jpg' in ''.join(files):\n",
    "        test_flist += [ cpath + '/' + f for f in files if 'checkpoint' not in cpath and np.sum(cv.imread(cpath + '/' + f)) !=0 ]\n",
    "            \n",
    "random.shuffle(train_flist)\n",
    "\n",
    "test_flist = test_flist + val_flist\n",
    "\n",
    "\n",
    "train_lb = [ 1 if f.split('/')[2] == 'blink' or f.split('/')[2] == 'close' or f.split('/')[3] == 'close' else 0 for f in train_flist ]\n",
    "val_lb = [ 1 if f.split('/')[2] == 'blink' or f.split('/')[2] == 'close' or f.split('/')[3] == 'close' else 0 for f in val_flist ]\n",
    "test_lb = [ 1 if f.split('/')[2] == 'blink' or f.split('/')[2] == 'close' or f.split('/')[3] == 'close' else 0 for f in test_flist ]\n",
    "\n",
    "len(train_flist), len(val_flist),len(test_flist), len(train_lb), len(val_lb), len(test_lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps_per_epoch = math.ceil(len(train_flist) / BATCH_SIZE)\n",
    "test_steps_per_epoch = math.ceil(len(test_flist) / BATCH_SIZE)\n",
    "val_steps_per_epoch = math.ceil(len(val_flist) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kFK348gIVIVH"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_img(path, mode='train', trans = [0, 2, 1, 3]):\n",
    "    \n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.rgb_to_grayscale(img)\n",
    "\n",
    "    if mode =='train':\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        \n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.per_image_standardization(img)\n",
    "\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE*FRAME))\n",
    "    img = tf.reshape(img, (IMG_SIZE, FRAME,IMG_SIZE, CHANNEL))\n",
    "    img = tf.transpose(img, trans)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def get_dataset(flist , lbs, mode = 'train', trans = [0 , 2, 1, 3]): # [1, 0, 2, 3]\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices( flist )\n",
    "    dataset_lb = tf.data.Dataset.from_tensor_slices( lbs )\n",
    "    \n",
    "    dataset = dataset.map(lambda x: get_img(x, mode, trans), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = tf.data.Dataset.zip((dataset, dataset_lb))\n",
    "\n",
    "    if mode == 'train':\n",
    "        dataset = dataset.repeat()\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE)      \n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3Dcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn3d(fid):\n",
    "    \n",
    "    train_dataset = get_dataset(train_flist, train_lb, mode = 'train', trans = [0 , 2, 1, 3])\n",
    "    val_dataset = get_dataset(val_flist, val_lb, mode = 'test', trans = [0 , 2, 1, 3])\n",
    "    test_dataset = get_dataset(test_flist, test_lb, mode = 'test', trans = [0 , 2, 1, 3])\n",
    "    \n",
    "    SEED = 42\n",
    "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "    keras.utils.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv3D(32, kernel_size=(3, 3, 3), activation='relu', \n",
    "                               padding = 'same',input_shape=(IMG_SIZE,IMG_SIZE,FRAME,CHANNEL)),\n",
    "        tf.keras.layers.MaxPooling3D(),\n",
    "        tf.keras.layers.Conv3D(32, 3, padding = 'same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling3D(),\n",
    "        tf.keras.layers.Conv3D(64, 3, padding = 'same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling3D(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1) \n",
    "    ])\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(train_dataset, steps_per_epoch=train_steps_per_epoch, \n",
    "              epochs=EPOCHS, validation_data=val_dataset, validation_steps= val_steps_per_epoch, \n",
    "              callbacks=[tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='model/3DCNN_{}'.format(fid),save_best_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',)], verbose=1)\n",
    "\n",
    "    best_model = keras.models.load_model('model/3DCNN_{}'.format(fid))\n",
    "\n",
    "    preds = tf.nn.sigmoid(best_model.predict(test_dataset)).numpy().ravel()\n",
    "    pd.DataFrame( np.array([test_flist, preds]).T, columns=['path', 'pred']).to_csv('{}/3DCNN_{}.csv'.format(RESULT_PATH, fid),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cnn_():\n",
    "    model = keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, input_shape=(IMG_SIZE, IMG_SIZE, CHANNEL), padding='same', activation='relu'))    \n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')) \n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')) \n",
    "    model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    #model.add(tf.keras.layers.Dropout(0.5))\n",
    "    #model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def cnnlstm(fid):\n",
    "\n",
    "    train_dataset = get_dataset(train_flist, train_lb, mode = 'train', trans = [1, 0, 2, 3])\n",
    "    test_dataset = get_dataset(test_flist, test_lb, mode = 'test', trans =[1, 0, 2, 3])\n",
    "    val_dataset = get_dataset(val_flist, val_lb, mode = 'test',  trans =[1, 0, 2, 3])\n",
    "\n",
    "    SEED = 42\n",
    "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "    keras.utils.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    convnet = cnn_()\n",
    "    model.add(tf.keras.layers.TimeDistributed(convnet, input_shape=(FRAME,IMG_SIZE, IMG_SIZE, CHANNEL)))\n",
    "    model.add(tf.keras.layers.LSTM(64))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(train_dataset, steps_per_epoch=train_steps_per_epoch, \n",
    "              epochs=EPOCHS, validation_data=val_dataset, validation_steps= val_steps_per_epoch, \n",
    "              callbacks=[tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='model/CNNLSTM_{}'.format(fid),save_best_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',)], verbose=1)\n",
    "\n",
    "    best_model = keras.models.load_model('model/CNNLSTM_{}'.format(fid))\n",
    "    \n",
    "    preds = tf.nn.sigmoid(best_model.predict(test_dataset)).numpy().ravel()\n",
    "    pd.DataFrame( np.array([test_flist, preds]).T, columns=['path', 'pred']).to_csv('{}/CNNLSTM_{}.csv'.format(RESULT_PATH, fid),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyramid 3DCNN\n",
    "### https://www.sciencedirect.com/science/article/pii/S0893608022001423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P2B2(fid):\n",
    "    # starting  block\n",
    "    input_ = tf.keras.Input(shape=INPUT_SHAPE) \n",
    "    x = tf.keras.layers.Conv3D(64, kernel_size=(3, 3, 3), strides=(1, 1, 2), padding = 'same')(input_)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling3D( pool_size=(3, 3, 3), strides=(1, 1, 2), padding = 'same')(x)\n",
    "    \n",
    "    \n",
    "    ## pyramid 1\n",
    "    # branch 1\n",
    "    x1 = tf.keras.layers.Conv3D(64, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "    # branch 2\n",
    "    x2 = tf.keras.layers.Conv3D(64, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "\n",
    "    x2 = tf.keras.layers.Conv3D(64, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    \n",
    "    \n",
    "    #last = tf.keras.Sequential()   \n",
    "    last = tf.keras.layers.Add()([x1,x2])   \n",
    "    last = tf.keras.layers.Activation('relu')(last)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## pyramid 2\n",
    "    # branch 1\n",
    "    x1 = tf.keras.layers.Conv3D(128, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(last)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "    # branch 2\n",
    "    x2 = tf.keras.layers.Conv3D(128, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(last)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "\n",
    "    x2 = tf.keras.layers.Conv3D(128, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    \n",
    "    \n",
    "    #last = tf.keras.Sequential()   \n",
    "    last = tf.keras.layers.Add()([x1,x2])    \n",
    "    last = tf.keras.layers.Activation('relu')(last)\n",
    "    \n",
    "    \n",
    "    last = tf.keras.layers.GlobalAveragePooling3D()(last)\n",
    "    last_out =tf.keras.layers.Dense(2, activation='softmax')(last)\n",
    "\n",
    "    model = tf.keras.Model(inputs = input_,outputs = last_out)\n",
    "    \n",
    "    \n",
    "    train_dataset = get_dataset(train_flist, train_lb, mode = 'train', trans = [0 , 2, 1, 3])\n",
    "    test_dataset = get_dataset(test_flist, test_lb, mode = 'test', trans =[0 , 2, 1, 3])\n",
    "    val_dataset = get_dataset(val_flist, val_lb, mode = 'test',   trans =[0 , 2, 1, 3])\n",
    "\n",
    "    SEED = 42\n",
    "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "    keras.utils.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(train_dataset, steps_per_epoch=train_steps_per_epoch, \n",
    "              epochs=EPOCHS, validation_data=val_dataset, validation_steps= val_steps_per_epoch, \n",
    "              callbacks=[tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='model/P2B2_{}'.format(fid),save_best_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',)], verbose=1)\n",
    "\n",
    "    best_model = keras.models.load_model('model/P2B2_{}'.format(fid))\n",
    "\n",
    "\n",
    "    preds = best_model.predict(test_dataset)[:,1]\n",
    "    pd.DataFrame( np.array([test_flist, preds]).T, columns=['path', 'pred']).to_csv('{}/P2B2_{}.csv'.format(RESULT_PATH, fid),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P2B3(fid):\n",
    "    # starting  block\n",
    "    input_ = tf.keras.Input(shape=INPUT_SHAPE) \n",
    "    x = tf.keras.layers.Conv3D(64, kernel_size=(3, 3, 3), strides=(1, 1, 2), padding = 'same')(input_)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling3D( pool_size=(3, 3, 3), strides=(1, 1, 2), padding = 'same')(x)\n",
    "    \n",
    "    \n",
    "    ## pyramid 1\n",
    "    # branch 1\n",
    "    x1 = tf.keras.layers.Conv3D(64, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "    # branch 2\n",
    "    x2 = tf.keras.layers.Conv3D(64, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "\n",
    "    x2 = tf.keras.layers.Conv3D(64, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    \n",
    "    # branch 3\n",
    "    x3 = tf.keras.layers.Conv3D(64, kernel_size=(5, 5, 3), strides=(1, 1, 1), padding = 'same')(x)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "\n",
    "    x3 = tf.keras.layers.Conv3D(64, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "\n",
    "    x3 = tf.keras.layers.Conv3D(64, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    \n",
    "    #last = tf.keras.Sequential()   \n",
    "    last = tf.keras.layers.Add()([x1,x2,x3])    \n",
    "    last = tf.keras.layers.Activation('relu')(last)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## pyramid 2\n",
    "    # branch 1\n",
    "    x1 = tf.keras.layers.Conv3D(128, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(last)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "    # branch 2\n",
    "    x2 = tf.keras.layers.Conv3D(128, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(last)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "\n",
    "    x2 = tf.keras.layers.Conv3D(128, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    \n",
    "    # branch 3\n",
    "    x3 = tf.keras.layers.Conv3D(128, kernel_size=(5, 5, 3), strides=(1, 1, 1), padding = 'same')(last)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "\n",
    "    x3 = tf.keras.layers.Conv3D(128, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "\n",
    "    x3 = tf.keras.layers.Conv3D(128, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    \n",
    "    #last = tf.keras.Sequential()   \n",
    "    last = tf.keras.layers.Add()([x1,x2,x3])    \n",
    "    last = tf.keras.layers.Activation('relu')(last)\n",
    "    \n",
    "    \n",
    "    last = tf.keras.layers.GlobalAveragePooling3D()(last)\n",
    "    last_out =tf.keras.layers.Dense(2, activation='softmax')(last)\n",
    "\n",
    "    model = tf.keras.Model(inputs = input_,outputs = last_out)\n",
    "    \n",
    "    \n",
    "    train_dataset = get_dataset(train_flist, train_lb, mode = 'train', trans = [0 , 2, 1, 3])\n",
    "    test_dataset = get_dataset(test_flist, test_lb, mode = 'test', trans =[0 , 2, 1, 3])\n",
    "    val_dataset = get_dataset(val_flist, val_lb, mode = 'test',   trans =[0 , 2, 1, 3])\n",
    "\n",
    "    SEED = 42\n",
    "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "    keras.utils.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    \n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='{}/P2B3_{}'.format(MODEL_PATH , fid),save_best_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(train_dataset, steps_per_epoch=train_steps_per_epoch, \n",
    "              epochs=EPOCHS, validation_data=val_dataset, validation_steps= val_steps_per_epoch, \n",
    "              callbacks=[tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='model/P2B3_{}'.format(fid),save_best_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',)], verbose=1)\n",
    "\n",
    "    best_model = keras.models.load_model('model/P2B3_{}'.format(fid))\n",
    "\n",
    "    preds = best_model.predict(test_dataset)[:,1]\n",
    "    pd.DataFrame( np.array([test_flist, preds]).T, columns=['path', 'pred']).to_csv('{}/P2B3_{}.csv'.format(RESULT_PATH, fid),index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P3B3(fid):\n",
    "    # starting  block\n",
    "    \n",
    "    input_ = tf.keras.Input(shape=INPUT_SHAPE) \n",
    "    x = tf.keras.layers.Conv3D(64, kernel_size=(3, 3, 3), strides=(1, 1, 2), padding = 'same')(input_)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling3D(pool_size=(3, 3, 3), strides=(1, 1, 2), padding = 'same')(x)\n",
    "    \n",
    "    \n",
    "    ## pyramid 1\n",
    "    # branch 1\n",
    "    x1 = tf.keras.layers.Conv3D(64, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "    # branch 2\n",
    "    x2 = tf.keras.layers.Conv3D(64, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(x)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "\n",
    "    x2 = tf.keras.layers.Conv3D(64, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "    # branch 3\n",
    "    x3 = tf.keras.layers.Conv3D(64, kernel_size=(5, 5, 3), strides=(1, 1, 1), padding = 'same')(x)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "\n",
    "    x3 = tf.keras.layers.Conv3D(64, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "\n",
    "    x3 = tf.keras.layers.Conv3D(64, kernel_size=(1, 1, 3), strides=(2, 2, 1),  padding = 'same')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "\n",
    "    #last = tf.keras.Sequential()   \n",
    "    last = tf.keras.layers.Add()([x1,x2,x3])    \n",
    "    last = tf.keras.layers.Activation('relu')(last)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## pyramid 2\n",
    "    # branch 1\n",
    "    x1 = tf.keras.layers.Conv3D(128, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(last)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "    # branch 2\n",
    "    x2 = tf.keras.layers.Conv3D(128, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(last)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "\n",
    "    x2 = tf.keras.layers.Conv3D(128, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "    # branch 3\n",
    "    x3 = tf.keras.layers.Conv3D(128, kernel_size=(5, 5, 3), strides=(1, 1, 1), padding = 'same')(last)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "\n",
    "    x3 = tf.keras.layers.Conv3D(128, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "\n",
    "    x3 = tf.keras.layers.Conv3D(128, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "\n",
    "    #last = tf.keras.Sequential()   \n",
    "    last = tf.keras.layers.Add()([x1,x2,x3])    \n",
    "    last = tf.keras.layers.Activation('relu')(last)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     ## pyramid 3\n",
    "    # branch 1\n",
    "    x1 = tf.keras.layers.Conv3D(192, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(last)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "\n",
    "    # branch 2\n",
    "    x2 = tf.keras.layers.Conv3D(192, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(last)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "    x2 = tf.keras.layers.Activation('relu')(x2)\n",
    "\n",
    "    x2 = tf.keras.layers.Conv3D(192, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "\n",
    "    # branch 3\n",
    "    x3 = tf.keras.layers.Conv3D(192, kernel_size=(5, 5, 3), strides=(1, 1, 1), padding = 'same')(last)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "\n",
    "    x3 = tf.keras.layers.Conv3D(192, kernel_size=(3, 3, 3), strides=(1, 1, 1), padding = 'same')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "    x3 = tf.keras.layers.Activation('relu')(x3)\n",
    "\n",
    "    x3 = tf.keras.layers.Conv3D(192, kernel_size=(1, 1, 3), strides=(2, 2, 1), padding = 'same')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "\n",
    "    #last = tf.keras.Sequential()   \n",
    "    last = tf.keras.layers.Add()([x1,x2,x3])    \n",
    "    last = tf.keras.layers.Activation('relu')(last)\n",
    "    \n",
    "    last = tf.keras.layers.GlobalAveragePooling3D()(last)\n",
    "    last_out = tf.keras.layers.Dense(2, activation='softmax')(last)\n",
    "\n",
    "    model = tf.keras.Model(inputs = input_, outputs = last_out)\n",
    "    \n",
    "    \n",
    "    train_dataset = get_dataset(train_flist, train_lb, mode = 'train', trans = [0 , 2, 1, 3])\n",
    "    test_dataset = get_dataset(test_flist, test_lb, mode = 'test', trans =[0 , 2, 1, 3])\n",
    "    val_dataset = get_dataset(val_flist, val_lb, mode = 'test',   trans =[0 , 2, 1, 3])\n",
    "\n",
    "    SEED = 42\n",
    "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "    keras.utils.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(train_dataset, steps_per_epoch=train_steps_per_epoch, \n",
    "              epochs=EPOCHS, validation_data=val_dataset, validation_steps= val_steps_per_epoch, \n",
    "              callbacks=[tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='model/P3B3_{}'.format(fid),save_best_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',)], verbose=1)\n",
    "\n",
    "    best_model = keras.models.load_model('model/P3B3_{}'.format(fid))\n",
    "\n",
    "    preds = best_model.predict(test_dataset)[:,1]\n",
    "    pd.DataFrame( np.array([test_flist, preds]).T, columns=['path', 'pred']).to_csv('{}/P3B3_{}.csv'.format(RESULT_PATH, fid),index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YtbqCVOVIVK"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "# cross validation\n",
    "for fid in range(1,6):\n",
    "    cnnlstm(fid)\n",
    "\n",
    "\n",
    "for fid in range(1,6):\n",
    "    cnn3d(fid)\n",
    "\n",
    "for fid in range(1,6):\n",
    "    P2B2(fid)\n",
    "\n",
    "for fid in range(1,6):\n",
    "    P2B3(fid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "vivit",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf2.8",
   "language": "python",
   "name": "tf2.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
